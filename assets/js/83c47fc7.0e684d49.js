"use strict";(self.webpackChunkuniversity=self.webpackChunkuniversity||[]).push([[3088],{8738:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>r,toc:()=>d});var a=n(5893),i=n(1151);const s={title:"Master data hub: Using API",sidebar_label:"Using API",sidebar_position:6},o="Using API",r={id:"learn/master-data-hub/using-api",title:"Master data hub: Using API",description:"Dataset differential update using API",source:"@site/docs/learn/master-data-hub/using-api.md",sourceDirName:"learn/master-data-hub",slug:"/learn/master-data-hub/using-api",permalink:"/docs/learn/master-data-hub/using-api",draft:!1,unlisted:!1,editUrl:"https://github.com/rossumai/university/tree/master/docs/learn/master-data-hub/using-api.md",tags:[],version:"current",sidebarPosition:6,frontMatter:{title:"Master data hub: Using API",sidebar_label:"Using API",sidebar_position:6},sidebar:"learnSidebar",previous:{title:"Full dataset replace",permalink:"/docs/learn/master-data-hub/full-dataset-replace"},next:{title:"NetSuite",permalink:"/docs/learn/netsuite/"}},l={},d=[{value:"Dataset differential update using API",id:"dataset-differential-update-using-api",level:2},{value:"Recommended implementation",id:"recommended-implementation",level:3},{value:"General description",id:"general-description",level:4},{value:"Implementation steps",id:"implementation-steps",level:4},{value:"Downloading whole collections using API",id:"downloading-whole-collections-using-api",level:2}];function c(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",...(0,i.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"using-api",children:"Using API"})}),"\n",(0,a.jsx)(t.h2,{id:"dataset-differential-update-using-api",children:"Dataset differential update using API"}),"\n",(0,a.jsx)(t.p,{children:"This part describes best practices for implementation of the differential updates of the dataset stored in the Rossum's Master Data Hub (MDH) using the API."}),"\n",(0,a.jsx)(t.h3,{id:"recommended-implementation",children:"Recommended implementation"}),"\n",(0,a.jsx)(t.h4,{id:"general-description",children:"General description"}),"\n",(0,a.jsx)(t.p,{children:"The MDS's API for the replication of the datasets is file based and asynchronous. The client sending the file to the endpoint does not get the status of the replication run in the response to the call of the replication endpoint (the replication can take minutes depending on the size of the file). The first call however returns ID of the operation that can be then monitored using other API endpoint and the result of the replication job can be determined based on the operation status."}),"\n",(0,a.jsx)(t.h4,{id:"implementation-steps",children:"Implementation steps"}),"\n",(0,a.jsxs)(t.ol,{children:["\n",(0,a.jsxs)(t.li,{children:["Call ",(0,a.jsx)(t.a,{href:"https://elis.rossum.ai/api/docs/#login",children:"login endpoint"})," of Rossum API to obtain access token that will be used for authentication of the dataset file push call. The username and password is required for this call. There can be an integration user created for this purpose in Rossum."]}),"\n",(0,a.jsxs)(t.li,{children:["Call the ",(0,a.jsx)(t.a,{href:"https://elis.rossum.ai/svc/data-matching/api/docs#tag/Dataset/operation/update_dataset_api_v1_dataset__dataset_name__patch",children:"Dataset Update"})," endpoint of the MDH API.","\n",(0,a.jsxs)(t.ol,{children:["\n",(0,a.jsxs)(t.li,{children:["It is assumed that the file that you are sending contains records to be upserted (inserted or updated) in the target dataset, and it is therefore necessary to specify the ",(0,a.jsx)(t.code,{children:"id_keys"})," parameter to tell the system how to uniquely identify the record, so it can either update existing or determine that it does not exist and import it."]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(t.li,{children:"The dataset operations are asynchronous and the API calls will return the ID of the operation in the Location header of the reply."}),"\n",(0,a.jsxs)(t.li,{children:["The operation should be monitored after the call by repeated calls (every 30 seconds or so) of the ",(0,a.jsx)(t.a,{href:"https://elis.rossum.ai/svc/data-matching/api/docs#tag/Operation/operation/get_operation_api_v1_operation__operation_id__get",children:"Get Operation"})," endpoint."]}),"\n",(0,a.jsx)(t.li,{children:"If the operation finishes successfully the job ends."}),"\n",(0,a.jsx)(t.li,{children:"If the operation fails or takes longer than 30 minutes the API call should be retried (3 retries are recommended)."}),"\n",(0,a.jsx)(t.li,{children:"If all retries fail the whole job can be considered failed and should produce an alert in the monitoring system."}),"\n"]}),"\n",(0,a.jsx)(t.h2,{id:"downloading-whole-collections-using-api",children:"Downloading whole collections using API"}),"\n",(0,a.jsxs)(t.p,{children:["It might be useful to download the whole collection to update it locally or to analyze its structure. This is currently not possible via UI but can be achieved using simple ",(0,a.jsx)(t.a,{href:"https://nodejs.org/en",children:"Node.js"})," script. Download it locally, change the token and collection name in the script and run it (no external libraries are needed):"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"node download_collection.js\n"})}),"\n",(0,a.jsx)(t.p,{children:"Source code:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-js",children:"const fs = require('fs');\n\nconst ROSSUM_TOKEN = '__CHANGE_ME__';\nconst COLLECTION_NAME = '__CHANGE_ME__';\nconst BASE_URL = 'https://elis.rossum.ai/svc/data-storage/api/v1';\nconst FIND_ENDPOINT = `${BASE_URL}/data/find`;\n\nasync function* downloadCollection(collectionName, token) {\n  let startIndex = 0;\n  const batchSize = 2500;\n  const maxRetries = 5;\n  const retryDelay = 5000; // Delay between retries in milliseconds\n\n  while (true) {\n    const payload = {\n      collectionName: collectionName,\n      query: {},\n      projection: { _id: 0 },\n      skip: startIndex,\n      limit: batchSize,\n      sort: { _id: -1 },\n    };\n\n    const headers = {\n      'Content-Type': 'application/json',\n      'Accept': 'application/json',\n      'Authorization': `Bearer ${token}`,\n    };\n\n    let attempts = 0;\n    let success = false;\n    let data;\n\n    // Retry logic\n    while (attempts < maxRetries && !success) {\n      try {\n        console.log(FIND_ENDPOINT, JSON.stringify(payload));\n        const response = await fetch(FIND_ENDPOINT, {\n          method: 'POST',\n          headers: headers,\n          body: JSON.stringify(payload),\n        });\n\n        if (!response.ok) {\n          throw new Error(`Fetch failed with status ${response.status}`);\n        }\n\n        data = await response.json();\n        success = true;\n      } catch (error) {\n        attempts++;\n        console.error(`Attempt ${attempts} failed: ${error.message}`);\n        if (attempts < maxRetries) {\n          await new Promise((resolve) => setTimeout(resolve, retryDelay)); // Wait before retrying\n        } else {\n          throw new Error('Max retries reached. Aborting.');\n        }\n      }\n    }\n\n    const documents = data.result;\n\n    // Break the loop if no more documents are returned\n    if (!documents || documents.length === 0) {\n      break;\n    }\n\n    // Yield the documents as they are fetched\n    yield documents;\n\n    // Update the start index for the next batch\n    startIndex += batchSize;\n  }\n}\n\n(async () => {\n  const fileStream = fs.createWriteStream(`${COLLECTION_NAME}.json`);\n  fileStream.write('['); // Start the array\n\n  let firstBatch = true;\n\n  for await (const documents of downloadCollection(COLLECTION_NAME, ROSSUM_TOKEN)) {\n    if (!firstBatch) {\n      fileStream.write(','); // Separate batches with commas\n    }\n    fileStream.write(JSON.stringify(documents).slice(1, -1)); // Remove the array brackets from each batch\n    firstBatch = false;\n  }\n\n  fileStream.write(']'); // End the array\n  fileStream.end();\n})();\n"})})]})}function h(e={}){const{wrapper:t}={...(0,i.a)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},1151:(e,t,n)=>{n.d(t,{Z:()=>r,a:()=>o});var a=n(7294);const i={},s=a.createContext(i);function o(e){const t=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),a.createElement(s.Provider,{value:t},e.children)}}}]);